{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Build) Dataset to token classification\n",
    "\n",
    "- Author: Didier Guillevic\n",
    "- Date: 2024-08-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We would like to build a Dataset instance with two columns: `'words'`, `'labels'`\n",
    "    - `'words'` will be a list of words\n",
    "    - `'labels'` will the labels (**as integers**) we wish to predict\n",
    "- Define the `label_names` as a list of strings; e.g.\n",
    "    ```\n",
    "        label_names = [\n",
    "            'O',\n",
    "            'B-STREET_NB', 'I-STREET_NB',\n",
    "            'B-STREET_NAME', 'I-STREET_NAME',\n",
    "            'B-UNIT', 'I-UNIT',\n",
    "            'B-CITY', 'I-CITY',\n",
    "            'B-REGION', 'I-REGION',\n",
    "            'B-POSTCODE', 'I-POSTCODE'\n",
    "        ]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "\t\"train\": \"openaddresses_ca_train.parquet\",\n",
    "\t\"validation\": \"openaddresses_ca_validation.parquet\",\n",
    "\t\"test\": \"openaddresses_ca_test.parquet\"\n",
    "}\n",
    "#data_files_dev = {\n",
    "#    \"train\": \"openaddresses_ca_test.parquet\",\n",
    "#}\n",
    "dataset = load_dataset(\"parquet\", data_files=data_files)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The addresses have been post-normalized in the OpenAddresses dataset.\n",
    "- They need to preprocess so they look like what people might have actually\n",
    "  written (i.e. before the addresses were normalized).\n",
    "- Tasks:\n",
    "    - lowercase all texts: sreet, unit, city, region, postcode\n",
    "    - add (randomly) a space between the first and last 3 characters of a postal\n",
    "      code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postal code\n",
    "\n",
    "- The postal code has been normalized as a 6 character string with no space.\n",
    "- I believe people would write the postal code with a space between the first\n",
    "  and last 3 characters.\n",
    "- Hence, randomly (1 chance out of 2) adding a space between the first and last\n",
    "  3 characters of the postal code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_split_postcode(example):\n",
    "    \"\"\"Randomly add a space between first 3 and last 3 characters of postcode\"\"\"\n",
    "    return {\n",
    "        'postcode': (\n",
    "            (example['postcode'][:3] + ' ' + example['postcode'][3:]) if\n",
    "            (example['postcode'] and len(example['postcode']) == 6 and random.randint(0, 1)) else \n",
    "            example['postcode']\n",
    "        )\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(rand_split_postcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][:8]['postcode']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region (provinces)\n",
    "\n",
    "- The regions (provinces) have been normalized to be 2 letter codes; e.g.\n",
    "\"QC\", \"ON\", \"BC\", ...\n",
    "- Hence, the model will not be able to recognize that \"British Columbia\" might\n",
    "  stand for the \"BC\" region.\n",
    "- We will randomly replace the 2 letter codes with the expanded versions\n",
    "  (ideally both French and English version where appropriate); e.g.\n",
    "  - \"BC -> {\"British Columbia\", \"Colombie Britannique\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(set(dataset['train']['region']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some alternative for each region\n",
    "region_alts = {\n",
    "    'AB': ['Alberta',],\n",
    "    'BC': ['British Columbia', \"Colombie Britannique\"],\n",
    "    'MB': ['Manitoba',],\n",
    "    'NB': ['New Brunswick', 'Nouveau Brunswick'],\n",
    "    'NL': ['Newfoundland and Labrador', 'Terre Neuve et Labrador'],\n",
    "    'NS': ['Nova Scotia', 'Nouvelle Écosse'],\n",
    "    'NT': ['Northwest Territories', 'Territoires du Nord Ouest'],\n",
    "    'NU': ['Nunavut',],\n",
    "    'ON': ['Ontario',],\n",
    "    'PE': ['PEI', 'Prince Edward Island', 'Île du Prince Édouard'],\n",
    "    'QC': ['Quebec', 'Québec'],\n",
    "    'SK': ['Saskatchewan',],\n",
    "    'YT': ['Yukon', 'Yukon Territory']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_alt_region(example):\n",
    "    \"\"\"Randomly substitute the 2 character code region with an alternate form\"\"\"\n",
    "    return {\n",
    "        'region': (\n",
    "            random.choice(region_alts[example['region']]) if\n",
    "            (example['region'] and example['region'] in region_alts and random.randint(0, 1)) else\n",
    "            example['region']\n",
    "        )\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(rand_alt_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][:5]['region']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(set(dataset['train']['unit']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowercase text\n",
    "\n",
    "The data has been normalized where the city names are in all uppercase.\n",
    "Probably easier to lowercase everything.\n",
    "Will need to test if the performance suffers at test / eval time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_columns(example):\n",
    "    for key, value in example.items():\n",
    "        if isinstance(value, str):\n",
    "            example[key] = value.lower() if value else value\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(lowercase_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add lists of words and labels\n",
    "\n",
    "1. We might want to randomly add a comma \",\" between the address components.\n",
    "2. Additionnally, we might wish to randomly omit the region and postal code to \n",
    "   simulate cases where that data would be present when in operational mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wish to create two new columns: words and labels\n",
    "label_names = [\n",
    "    'O',\n",
    "    'B-STREET_NB', 'I-STREET_NB',\n",
    "    'B-STREET_NAME', 'I-STREET_NAME',\n",
    "    'B-UNIT', 'I-UNIT',\n",
    "    'B-CITY', 'I-CITY',\n",
    "    'B-REGION', 'I-REGION',\n",
    "    'B-POSTCODE', 'I-POSTCODE'\n",
    "]\n",
    "label_name_to_id = {name: i for i, name in enumerate(label_names)}\n",
    "label_name_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_labelID = {\n",
    "    'number': 1,\n",
    "    'street': 3,\n",
    "    'unit': 5,\n",
    "    'city': 7,\n",
    "    'region': 9,\n",
    "    'postcode': 11\n",
    "}\n",
    "feature_to_labelID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create two new columns: words, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['number', 'street', 'unit', 'city', 'region', 'postcode']\n",
    "unit_alts = ['unit', 'suite', 'appt', '#']\n",
    "\n",
    "def build_words_labels(example):\n",
    "    all_words = []\n",
    "    all_labels = []\n",
    "\n",
    "    def add_word_label(word, label):\n",
    "        word = word.strip()\n",
    "        if not word:\n",
    "            return\n",
    "        words = word.split()\n",
    "        for i, w in enumerate(words):\n",
    "            all_words.append(w)\n",
    "            all_labels.append(label if (i == 0 or label == 0) else label+1)\n",
    "    \n",
    "    # CanadaPost recommends to put the unit number before the civic number,\n",
    "    # with both numbers separated by a hyphen.\n",
    "    # https://www.canadapost-postescanada.ca/cpc/en/support/kb/business/address-accuracy/addressing-mail-accurately#:~:text=Place%20the%20unit%20number%20before,province%20symbol%20by%202%20spaces.\n",
    "\n",
    "    # In the dataset, there are some unit values such \"1-2-3\".. Not ideal.\n",
    "    # So if hyphen present in the value, we will instead write \"suite 1-2-3\",\n",
    "    # or \"appt 1-2-3\" or \"#1-2-3\"\n",
    "\n",
    "    unit_pre = (\n",
    "        example['unit'] and ('-' not in example['unit']) and\n",
    "        example['number'] and random.randint(0, 1)\n",
    "    )\n",
    "\n",
    "    # unit\n",
    "    if unit_pre:\n",
    "        all_words.append(example['unit'])\n",
    "        all_labels.append(feature_to_labelID['unit'])\n",
    "        all_words.append(\"-\")\n",
    "        all_labels.append(0)\n",
    "        all_words.append(example['number'])\n",
    "        all_labels.append(feature_to_labelID['number'])\n",
    "    \n",
    "    # number\n",
    "    if not unit_pre and example['number']:\n",
    "        all_words.append(example['number'])\n",
    "        all_labels.append(feature_to_labelID['number'])\n",
    "    \n",
    "    # street\n",
    "    if example['street']:\n",
    "        add_word_label(example['street'], feature_to_labelID['street'])\n",
    "    \n",
    "    # unit\n",
    "    if not unit_pre and example['unit']:\n",
    "        # Randomly add a comma between address components (1 in 2 chance)\n",
    "        if random.randint(0, 1):\n",
    "            add_word_label(\",\", 0)\n",
    "\n",
    "        # randomly add a prefix to the unit number\n",
    "        if random.randint(0, 1):\n",
    "            add_word_label(random.choice(unit_alts), 0)\n",
    "        \n",
    "        add_word_label(example['unit'], feature_to_labelID['unit'])\n",
    "    \n",
    "    # city\n",
    "    if random.randint(0, 1):\n",
    "        add_word_label(\",\", 0)\n",
    "    add_word_label(example['city'], feature_to_labelID['city'])\n",
    "\n",
    "    # region (randomly omit 1 out of 5 chance)\n",
    "    if random.randint(0, 4) < 4:\n",
    "        if random.randint(0, 1):\n",
    "            add_word_label(\",\", 0)\n",
    "        add_word_label(example['region'], feature_to_labelID['region'])\n",
    "\n",
    "    # postcode (randomly omit 1 out of 5 chance)\n",
    "    if random.randint(0, 4) < 4:\n",
    "        if random.randint(0, 1):\n",
    "            add_word_label(\",\", 0)\n",
    "        add_word_label(example['postcode'], feature_to_labelID['postcode'])\n",
    "\n",
    "    return {'words': all_words, 'labels': all_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_token_classif = dataset.map(build_words_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_token_classif['train'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the label names as metadata in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save the list to a file\n",
    "with open(\"labels.json\", \"w\") as f:\n",
    "    json.dump(label_names, f)\n",
    "\n",
    "# Load the list from the file\n",
    "with open(\"labels.json\", \"r\") as f:\n",
    "    loaded_labels = json.load(f)\n",
    "\n",
    "print(loaded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep only the columns: 'words', 'labels'. This will save space when saving to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['number', 'street', 'unit', 'city', 'region', 'postcode', 'coordinates']\n",
    "dataset_to_save = dataset_token_classif.remove_columns(columns_to_remove)\n",
    "dataset_to_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the dataset ready for finetuning a token classifier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_preprocessed_name = \"openaddresses_ca_preprocessed_token_classif\"\n",
    "for split, dataset in dataset_to_save.items():\n",
    "    dataset.to_parquet(f\"{dataset_preprocessed_name}_{split}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
